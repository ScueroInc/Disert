{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoqLRVNchY8xaSSFhsaZzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ScueroInc/Disert/blob/main/Ejercicios/MLP%20Backpropagation%20Imp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "n5ojpLwRfzfc",
        "outputId": "04adfe18-0074-4e73-cd0d-e2bfbf6fc859"
      },
      "source": [
        "from math import exp\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        "\n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        "\n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        "\n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        "\n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "\n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        "\n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs,errores):\n",
        "\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tsum_error = 0\n",
        "\n",
        "\t\tfor row in train:\n",
        "\n",
        "\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\texpected[row[-1]] = 1\n",
        "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\tupdate_weights(network, row, l_rate)\n",
        "    \n",
        "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        "\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))\n",
        "# Test training backprop algorithm\n",
        "seed(1)\n",
        "dataset = [\n",
        "  [0,0,0],\n",
        "\t[0,1,1],\n",
        "\t[1,0,1],\n",
        "\t[1,1,0],\n",
        "  ]\n",
        "errores=[]\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = initialize_network(n_inputs, 2, n_outputs)\n",
        "train_network(network, dataset, 0.5, 4000, n_outputs,errores)\n",
        "for layer in network:\n",
        "\tprint(layer)\n",
        " \n",
        "\n",
        " \n",
        "for row in dataset:\n",
        " prediction = predict(network, row)\n",
        " print('Expected=%d, Got=%d' % (row[-1], prediction))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-fd298a97a22e>\"\u001b[0;36m, line \u001b[0;32m87\u001b[0m\n\u001b[0;31m    print(\"ga\")\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    }
  ]
}